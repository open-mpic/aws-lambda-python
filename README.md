# aws-lambda-python
An implementation of the Open MPIC API using AWS-Lambda serverless functions written in Python as well as AWS API Gateway.

# Deployment
As this API runs serverless in the cloud, it is not installed but rather deployed. The below instructions deploy the API in a user's AWS account and create a unique API endpoint for that user.

## Requirements
All requirements for running the API are packaged and uploaded to AWS as a lambda layer. However, the machine deploying the API must have the following requirements
- The AWS CLI (https://aws.amazon.com/cli/) installed with default profile login credentials. The script currently uses the "default" profile to deploy the API to. If you have multiple AWS profiles, ensure the one you want to use for the API in listed as default in ~/.aws/credentials. You can alternatively change the AWS module parameters in main.tf to use an alternate profile.
- Open Tofu (https://opentofu.org/) is installed. This is an open-source fork of Terraform and the configs in this project are largely interoperable between the two.
- Python 3.11.9 which can be run with the command `python3.11` and `python3`. [pyenv](https://github.com/pyenv/pyenv) is one option for getting this specific version of python and not modifying any other python installs on the system.
- Bash. Several deployment scripts are written for bash.
- Hatch (https://hatch.pypa.io/) for building and running the project. This is a Python project manager that can be installed via `pip install hatch`.

## Deployment Steps
1. Create `config.yaml` in the root directory of the repo to contain the proper values needed for the deployment. A default config.yaml for a 6-perspective deployment with the controller in us-east-2 is included in this repo as `config.example.yaml`. This config can be made the active config by running `cp config.example.yaml config.yaml` in the root directory.
2. Create a virtual Python environment in the `layer` directory and install the project dependencies via pip. This can be executed by running `hatch run lambda:layer-install`.
3. Package two AWS layers by executing `package-layer.sh`. This will make two files: `python3_layer_content.zip` and `mpic_coordinator_layer_content.zip` which will later be referenced by Open Tofu. This can be done by running `./package-layer.sh` or `hatch run lambda:layer-package`.
4. Run `configure.py` from the root directory of the repo to generate Open Tofu files from templates. This can be separately executed by running `hatch run ./configure.py` or `hatch run lambda:configure-tf`.
5. Zip all Lambda functions. AWS Lambda functions are usually deployed from zip files. This can be separately executed by running `./zip-all.sh` or `hatch run lambda:zip-all`.
6. Deploy the entire package with Open Tofu. cd to the `open-tofu` directory where .tf files are located. Then run `tofu init`. Then run `tofu apply` and type `yes` at the confirmation prompt. This provides a standard install with DNSSEC enabled which causes the system to incur expenses even when it is not in use (due to the AWS VPC NAT Gateways needed). To reduce the AWS bill, DNSSEC can also be disabled by appending `-var="dnssec_enabled=false"` to `tofu apply` (i.e., `tofu apply -var="dnssec_enabled=false"`).
7. Get the URL of the deployed API endpoint by running `hatch run ./get_api_url.py` in the root directory.
8. Get the API Key generated by AWS by running `hatch run ./get_api_key.py` in the root directory. The deployment is configured to reject any API call that does not have this key passed via the `x-api-key` HTTP header.

For convenience `./deploy.sh` in the project root will clean the environment and perform all of these steps (using `-var="dnssec_enabled=false"`), with the exception of copying over the example config to the operational config and running `tofu init` in the open-tofu dir.
In addition, `hatch run lambda:prepare` will run steps 2-5 in a single command.
Finally, `hatch run lambda:deploy` will clean the environment and then run steps 2-6, in the same manner as `deploy.sh`.

## Testing
The following is an example of a test API call that uses bash command substitution to fill in the proper values for the API URL and the API key.

```
curl -H 'Content-Type: application/json' -H "x-api-key: $(hatch run ./get_api_key.py)" \
      -d '{
  "check_type": "caa",
  "domain_or_ip_target": "example.com"
}' \
      -X POST \
      "$(hatch run ./get_api_url.py)/mpic"
```

The above sample must be run from the root directory of a deployed Open MPIC aws-lambda-python implementation for the bash command substitution to work. You can also run `hatch run ./get_api_key.py` and `hatch run ./get_api_url.py`, store these values and then substitute them into the above command. Once deployed, the API is globally accessible and authenticates requests via the `x-api-key` header, so the curl command with both of these values substituted can be run from any Internet-connected machine to trigger the API.

The API is compliant with the [Open MPIC Specification](https://github.com/open-mpic/open-mpic-specification).

Documentation based on the API specification used in this version can be viewed [here](https://open-mpic.org/documentation.html?commit=f763382c38a867dda3253afded017f9e3a24ead5).

## Development
Code changes can easily be deployed by editing the .py files and then rezipping the project via `./zip-all.sh` and `./2-package.sh` in the `layer` directory. Then, running `tofu apply` run from the open-tofu directory will update only on the required resources and leave the others unchanged. If any `.tf.template` files are changed or `config.yaml` is edited, `hatch run ./configure.py` must be rerun followed by `tofu apply` in the open-tofu directory.

`.generated.tf` files should not be edited directly and are not checked into git. Edit `.tf.template` files and regenerate the files via `./configure.py`.

### Unit Testing
Pytest is used for unit testing. To run the tests, use any of the following commands from the root directory of the project:
```
python -m pytest tests/unit
```
```
hatch test
```
```
hatch run test:unit
```
To generate an HTML coverage report (located in `htmlcov/index.html`), run:
```
hatch run test:coverage
```

Tests are configured in `pyproject.toml` 

If you encounter issues running unit tests with any of these commands, contact the project maintainers.

### Integration Testing
Pytest also runs integration tests in this project. These tests are currently intended to run against a deployed, live API, so they are effectively end-to-end tests. To run the tests, use either of the following commands:
```
python -m pytest tests/integration
```
```
hatch test tests/integration
```
```
hatch run test:integration
```
Note: integration tests cannot currently be invoked by running `pytest tests/integration` because `PYTHONPATH` is not set correctly in that case.

The integration tests test a live, deployed API and point the API at real web resources that are provisioned for testing purposes. The integration test content is currently hosted on `caatestsuite.com` (maintained by SSLMate) and `integration-testing.open-mpic.org` (maintained by the maintainers of the Open MPIC project). The zone file for `caatestsuite.com` can be found [here](https://github.com/SSLMate/caatestsuite) along with more info about the tests at [caatestsuite.com](https://caatestsuite.com), and the zone file for `integration-testing.open-mpic.org` can be found [here](https://github.com/open-mpic/open-mpic-integration-zone). Both of these services are maintained on a best-effort basis. If there is an issue with integration tests, check the availability of these two services and the responses from the sub-domains used in the integration tests. THESE SERVICES ARE PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND. They are not intended for use outside of development integration testing (i.e., no excessive query volume, no use in production systems).

If you encounter issues running integration tests with the above commands, contact the project maintainers.


## Tear-down
If you would like to take the API down, run `tofu destroy` in the open-tofu directory and type `yes` at the prompt. This will remove all AWS resources created by Open Tofu for the API. **There is currently a situation where AWS takes a very long time to release internal IP prefix resources from a VPC upon teardown. This can lead to `tofu destroy` hanging for a long time.** One mitigation is that `tofu destroy` can be run (which deprovisions almost all resources within minutes) and then aborted several minutes later with crtl+c. Then, after several hours, `tofu destroy` can be rerun which will deprovision the remaining IP prefix resources after sufficient time has passed for AWS to register the IP prefix objects are no longer associated with the VPC.

After `tofu destroy`, `./clean.sh` in the root directory also clears generated/zip files.



# Remaining tasks

The Open MPIC project is currently under development. The work items remaining to a feature-complete production-level product include the following: (subject to change)

- Additional integration testing

Throughout the development process, we will address any GitHub issues raised, and may modify the API accordingly. We also welcome pull requests from the general community.

## Completed Tasks
- API Testing scripts and usage examples. completion date: 9/11/2024
- Automatic provisioning of lambda functions based on a configuration file. This will eliminate the need to create the lambda functions one by one and simply allow a single config file to specify the entire system configuration which is then deployed automatically. completion date: 6/29/2024
- Full conformance to the published [API specification](https://github.com/open-mpic/open-mpic-specification). Because development on the current implementation began as we were standardizing the API specification, there are currently some discrepancies that we plan to resolve. This update will make calls to the lambda API compliant with the specification. completion date: 6/30/2024
- Refactoring to move non-AWS-specific functionality to a library (say lib-open-mpic) and contain AWS functionality in fewer files.

## Tasks without assigned timelines
There are several features that may be of interest to the community, but we don't yet have a specific completion timeline. These may be given higher priority based on feedback and community interest.

- Support for retrieval of contact information from whois and DNS for the purpose of validation. Several validation methods require contact information to be retrieved via multiple perspectives (e.g., email to domain CAA contact) which is then used in a subsequent validation step (that may not actually require MPIC). The API could support this by allowing a single API call to retrieve the contact info and then perform a set comparison (based on the quorum policy) to return contact info that could be used for validation.
- Support for CAA extensions. CAA issue tags can potentially have extensions to specify things like account ID or validation method per [RFC 8657](https://datatracker.ietf.org/doc/html/rfc8657). The API could potentially take validation method or account id as an optional parameter and perform the processing on these CAA extensions to have them correctly impact the API response.
